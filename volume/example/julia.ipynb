{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julia\n",
    "## Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 0.6.2\n",
      "Commit d386e40c17 (2017-12-13 18:08 UTC)\n",
      "Platform Info:\n",
      "  OS: Linux (x86_64-pc-linux-gnu)\n",
      "  CPU: Intel(R) Core(TM) i7-7820HK CPU @ 2.90GHz\n",
      "  WORD_SIZE: 64\n",
      "  BLAS: libopenblas (USE64BITINT DYNAMIC_ARCH NO_AFFINITY Prescott)\n",
      "  LAPACK: libopenblas64_\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-3.9.1 (ORCJIT, broadwell)\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mNo packages to install, update or remove\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPackage database updated\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mMETADATA is out-of-date â€” you may not have the latest version of Spark\n",
      "\u001b[39m\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUse `Pkg.update()` to get the latest versions of your packages\n",
      "\u001b[39m"
     ]
    }
   ],
   "source": [
    "Pkg.add(\"Spark.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mPrecompiling module DataStructures.\n",
      "\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /usr/local/jdk1.8.0_172/jre/lib/amd64/server/libjvm.so\n",
      "2018-06-14 15:36:06 INFO  SparkContext:54 - Running Spark version 2.3.0\n",
      "2018-06-14 15:36:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "2018-06-14 15:36:07 INFO  SparkContext:54 - Submitted application: Julia App on Spark\n",
      "2018-06-14 15:36:07 INFO  SecurityManager:54 - Changing view acls to: root\n",
      "2018-06-14 15:36:07 INFO  SecurityManager:54 - Changing modify acls to: root\n",
      "2018-06-14 15:36:07 INFO  SecurityManager:54 - Changing view acls groups to: \n",
      "2018-06-14 15:36:07 INFO  SecurityManager:54 - Changing modify acls groups to: \n",
      "2018-06-14 15:36:07 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\n",
      "2018-06-14 15:36:07 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 32923.\n",
      "2018-06-14 15:36:07 INFO  SparkEnv:54 - Registering MapOutputTracker\n",
      "2018-06-14 15:36:07 INFO  SparkEnv:54 - Registering BlockManagerMaster\n",
      "2018-06-14 15:36:07 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "2018-06-14 15:36:07 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up\n",
      "2018-06-14 15:36:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-9517a635-e497-4604-bccc-e99f0df388d7\n",
      "2018-06-14 15:36:07 INFO  MemoryStore:54 - MemoryStore started with capacity 398.7 MB\n",
      "2018-06-14 15:36:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator\n",
      "2018-06-14 15:36:07 INFO  log:192 - Logging initialized @1614ms\n",
      "2018-06-14 15:36:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT\n",
      "2018-06-14 15:36:07 INFO  Server:414 - Started @1665ms\n",
      "2018-06-14 15:36:07 INFO  AbstractConnector:278 - Started ServerConnector@54fdc218{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
      "2018-06-14 15:36:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@66629f63{/jobs,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@674c583e{/jobs/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@25f7391e{/jobs/job,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5ab14cb9{/jobs/job/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5fb97279{/stages,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@439a8f59{/stages/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61861a29{/stages/stage,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@32cb636e{/stages/stage/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@63cd604c{/stages/pool,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@40dd3977{/stages/pool/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3a4e343{/storage,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6a1d204a{/storage/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@62dae245{/storage/rdd,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4b6579e8{/storage/rdd/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6fff253c{/environment,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6c6357f9{/environment/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@591e58fa{/executors,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3954d008{/executors/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f94c4db{/executors/threadDump,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@593e824f{/executors/threadDump/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72ccd81a{/static,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4a8a60bc{/,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@361c294e{/api,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@664a9613{/jobs/job/kill,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5118388b{/stages/stage/kill,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://81b57c34d040:4040\n",
      "2018-06-14 15:36:07 INFO  Executor:54 - Starting executor ID driver on host localhost\n",
      "2018-06-14 15:36:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36333.\n",
      "2018-06-14 15:36:07 INFO  NettyBlockTransferService:54 - Server created on 81b57c34d040:36333\n",
      "2018-06-14 15:36:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "2018-06-14 15:36:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, 81b57c34d040, 36333, None)\n",
      "2018-06-14 15:36:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 81b57c34d040:36333 with 398.7 MB RAM, BlockManagerId(driver, 81b57c34d040, 36333, None)\n",
      "2018-06-14 15:36:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, 81b57c34d040, 36333, None)\n",
      "2018-06-14 15:36:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, 81b57c34d040, 36333, None)\n",
      "2018-06-14 15:36:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@410e94e{/metrics/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:07 INFO  SparkContext:54 - Added JAR /opt/julia/v0.6/Spark/src/../jvm/sparkjl/target/sparkjl-0.1.jar at spark://81b57c34d040:32923/jars/sparkjl-0.1.jar with timestamp 1528990567949\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparkContext(local,Julia App on Spark)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Spark\n",
    "Spark.init()\n",
    "sc = SparkContext(master=\"local\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-14 15:36:13 WARN  SparkContext:66 - Using an existing SparkContext; some configuration may not take effect.\n",
      "2018-06-14 15:36:13 INFO  SharedState:54 - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/root/volume/example/spark-warehouse').\n",
      "2018-06-14 15:36:13 INFO  SharedState:54 - Warehouse path is 'file:/root/volume/example/spark-warehouse'.\n",
      "2018-06-14 15:36:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3b8ee898{/SQL,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7d151a{/SQL/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77bb0ab5{/SQL/execution,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@f2c488{/SQL/execution/json,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:13 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@712ca57b{/static/sql,null,AVAILABLE,@Spark}\n",
      "2018-06-14 15:36:13 INFO  StateStoreCoordinatorRef:54 - Registered StateStoreCoordinator endpoint\n",
      "2018-06-14 15:36:15 INFO  FileSourceStrategy:54 - Pruning directories with: \n",
      "2018-06-14 15:36:15 INFO  FileSourceStrategy:54 - Post-Scan Filters: \n",
      "2018-06-14 15:36:15 INFO  FileSourceStrategy:54 - Output Data Schema: struct<value: string>\n",
      "2018-06-14 15:36:15 INFO  FileSourceScanExec:54 - Pushed Filters: \n",
      "2018-06-14 15:36:15 INFO  CodeGenerator:54 - Code generated in 190.277655 ms\n",
      "2018-06-14 15:36:15 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 276.8 KB, free 398.4 MB)\n",
      "2018-06-14 15:36:15 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.2 KB, free 398.4 MB)\n",
      "2018-06-14 15:36:15 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 81b57c34d040:36333 (size: 23.2 KB, free: 398.7 MB)\n",
      "2018-06-14 15:36:15 INFO  SparkContext:54 - Created broadcast 0 from json at <unknown>:0\n",
      "2018-06-14 15:36:15 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "2018-06-14 15:36:15 INFO  SparkContext:54 - Starting job: json at <unknown>:0\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Got job 0 (json at <unknown>:0) with 1 output partitions\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (json at <unknown>:0)\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Parents of final stage: List()\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Missing parents: List()\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[3] at json at <unknown>:0), which has no missing parents\n",
      "2018-06-14 15:36:15 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.4 KB, free 398.4 MB)\n",
      "2018-06-14 15:36:15 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.1 KB, free 398.4 MB)\n",
      "2018-06-14 15:36:15 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 81b57c34d040:36333 (size: 5.1 KB, free: 398.7 MB)\n",
      "2018-06-14 15:36:15 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039\n",
      "2018-06-14 15:36:15 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "2018-06-14 15:36:15 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 1 tasks\n",
      "2018-06-14 15:36:15 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8328 bytes)\n",
      "2018-06-14 15:36:15 INFO  Executor:54 - Running task 0.0 in stage 0.0 (TID 0)\n",
      "2018-06-14 15:36:15 INFO  Executor:54 - Fetching spark://81b57c34d040:32923/jars/sparkjl-0.1.jar with timestamp 1528990567949\n",
      "2018-06-14 15:36:16 INFO  TransportClientFactory:267 - Successfully created connection to 81b57c34d040/172.19.0.3:32923 after 22 ms (0 ms spent in bootstraps)\n",
      "2018-06-14 15:36:16 INFO  Utils:54 - Fetching spark://81b57c34d040:32923/jars/sparkjl-0.1.jar to /tmp/spark-f1e71a49-c618-4743-ab92-ed75a2211d62/userFiles-25100e7e-a903-4c14-a229-dd4a4f554ae3/fetchFileTemp7232726513333000763.tmp\n",
      "2018-06-14 15:36:16 INFO  Executor:54 - Adding file:/tmp/spark-f1e71a49-c618-4743-ab92-ed75a2211d62/userFiles-25100e7e-a903-4c14-a229-dd4a4f554ae3/sparkjl-0.1.jar to class loader\n",
      "2018-06-14 15:36:16 INFO  FileScanRDD:54 - Reading File path: file:///usr/local/spark/examples/src/main/resources/people.json, range: 0-73, partition values: [empty row]\n",
      "2018-06-14 15:36:16 INFO  CodeGenerator:54 - Code generated in 11.923968 ms\n",
      "2018-06-14 15:36:16 INFO  Executor:54 - Finished task 0.0 in stage 0.0 (TID 0). 1953 bytes result sent to driver\n",
      "2018-06-14 15:36:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 197 ms on localhost (executor driver) (1/1)\n",
      "2018-06-14 15:36:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool \n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - ResultStage 0 (json at <unknown>:0) finished in 0.238 s\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Job 0 finished: json at <unknown>:0, took 0.267487 s\n",
      "2018-06-14 15:36:16 INFO  FileSourceStrategy:54 - Pruning directories with: \n",
      "2018-06-14 15:36:16 INFO  FileSourceStrategy:54 - Post-Scan Filters: \n",
      "2018-06-14 15:36:16 INFO  FileSourceStrategy:54 - Output Data Schema: struct<age: bigint, name: string>\n",
      "2018-06-14 15:36:16 INFO  FileSourceScanExec:54 - Pushed Filters: \n",
      "2018-06-14 15:36:16 INFO  CodeGenerator:54 - Code generated in 10.969357 ms\n",
      "2018-06-14 15:36:16 INFO  CodeGenerator:54 - Code generated in 14.825119 ms\n",
      "2018-06-14 15:36:16 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 276.8 KB, free 398.1 MB)\n",
      "2018-06-14 15:36:16 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 23.2 KB, free 398.1 MB)\n",
      "2018-06-14 15:36:16 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 81b57c34d040:36333 (size: 23.2 KB, free: 398.6 MB)\n",
      "2018-06-14 15:36:16 INFO  SparkContext:54 - Created broadcast 2 from show at <unknown>:0\n",
      "2018-06-14 15:36:16 INFO  FileSourceScanExec:54 - Planning scan with bin packing, max size: 4194377 bytes, open cost is considered as scanning 4194304 bytes.\n",
      "2018-06-14 15:36:16 INFO  SparkContext:54 - Starting job: show at <unknown>:0\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Got job 1 (show at <unknown>:0) with 1 output partitions\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Final stage: ResultStage 1 (show at <unknown>:0)\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Parents of final stage: List()\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Missing parents: List()\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Submitting ResultStage 1 (MapPartitionsRDD[7] at show at <unknown>:0), which has no missing parents\n",
      "2018-06-14 15:36:16 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 11.1 KB, free 398.1 MB)\n",
      "2018-06-14 15:36:16 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.6 KB, free 398.1 MB)\n",
      "2018-06-14 15:36:16 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 81b57c34d040:36333 (size: 5.6 KB, free: 398.6 MB)\n",
      "2018-06-14 15:36:16 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at show at <unknown>:0) (first 15 tasks are for partitions Vector(0))\n",
      "2018-06-14 15:36:16 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 1 tasks\n",
      "2018-06-14 15:36:16 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8328 bytes)\n",
      "2018-06-14 15:36:16 INFO  Executor:54 - Running task 0.0 in stage 1.0 (TID 1)\n",
      "2018-06-14 15:36:16 INFO  FileScanRDD:54 - Reading File path: file:///usr/local/spark/examples/src/main/resources/people.json, range: 0-73, partition values: [empty row]\n",
      "2018-06-14 15:36:16 INFO  CodeGenerator:54 - Code generated in 10.177146 ms\n",
      "2018-06-14 15:36:16 INFO  Executor:54 - Finished task 0.0 in stage 1.0 (TID 1). 1262 bytes result sent to driver\n",
      "2018-06-14 15:36:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 1) in 37 ms on localhost (executor driver) (1/1)\n",
      "2018-06-14 15:36:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool \n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - ResultStage 1 (show at <unknown>:0) finished in 0.046 s\n",
      "2018-06-14 15:36:16 INFO  DAGScheduler:54 - Job 1 finished: show at <unknown>:0, took 0.047849 s\n",
      "+----+-------+\n",
      "| age|   name|\n",
      "+----+-------+\n",
      "|null|Michael|\n",
      "|  30|   Andy|\n",
      "|  19| Justin|\n",
      "+----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession()\n",
    "df = read_json(spark, \"/usr/local/spark/examples/src/main/resources/people.json\")\n",
    "show(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-06-14 15:36:21 INFO  AbstractConnector:318 - Stopped Spark@54fdc218{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\n",
      "2018-06-14 15:36:21 INFO  SparkUI:54 - Stopped Spark web UI at http://81b57c34d040:4040\n",
      "2018-06-14 15:36:21 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!\n",
      "2018-06-14 15:36:21 INFO  MemoryStore:54 - MemoryStore cleared\n",
      "2018-06-14 15:36:21 INFO  BlockManager:54 - BlockManager stopped\n",
      "2018-06-14 15:36:21 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped\n",
      "2018-06-14 15:36:21 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!\n",
      "2018-06-14 15:36:21 INFO  SparkContext:54 - Successfully stopped SparkContext\n"
     ]
    }
   ],
   "source": [
    "close(sc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
